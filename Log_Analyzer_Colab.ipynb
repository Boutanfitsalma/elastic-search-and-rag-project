{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üîç Analyseur de Structure des Logs Mozilla CI\n",
        "\n",
        "Ce notebook analyse la structure des logs pour identifier les patterns et pr√©parer le parsing.\n",
        "\n"
      ],
      "metadata": {
        "id": "title"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üì¶ 1: Installation des d√©pendances\n"
      ],
      "metadata": {
        "id": "cell1_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation des d√©pendances\n",
        "!pip install -q rarfile\n",
        "!apt-get install -qq unrar\n",
        "\n",
        "print(\"‚úÖ D√©pendances install√©es avec succ√®s!\")"
      ],
      "metadata": {
        "id": "cell1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaaa95df-fd4a-402b-9c67-4b925e56b805"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ D√©pendances install√©es avec succ√®s!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üì§ 2: Upload des fichiers .rar\n",
        "\n",
        "**3 fichiers .rar:**\n",
        "- log-2018-06-01.rar\n",
        "- log-2018-06-19.rar\n",
        "- log-2018-06-20.rar"
      ],
      "metadata": {
        "id": "cell2_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"üì§ Veuillez s√©lectionner vos fichiers .rar...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "print(f\"\\n‚úÖ {len(uploaded)} fichier(s) upload√©(s) avec succ√®s!\")"
      ],
      "metadata": {
        "id": "cell2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "4e90799f-0deb-4c8e-e6dd-bb55a9e4dad7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Veuillez s√©lectionner vos fichiers .rar...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9cc856f9-c888-4dc8-9da5-7e65b5462353\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9cc856f9-c888-4dc8-9da5-7e65b5462353\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving log-2018-06-19.rar to log-2018-06-19.rar\n",
            "Saving log-2018-06-20.rar to log-2018-06-20.rar\n",
            "Saving log-2018-06-01.rar to log-2018-06-01.rar\n",
            "\n",
            "‚úÖ 3 fichier(s) upload√©(s) avec succ√®s!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üöÄ 3: Analyse\n",
        "\n",
        "**Cette cellule contient tout le code d'analyse.**\n",
        "\n"
      ],
      "metadata": {
        "id": "cell3_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "from datetime import datetime\n",
        "import rarfile\n",
        "\n",
        "# Configuration\n",
        "SAMPLE_SIZE = 100  # Nombre de fichiers √† analyser par .rar\n",
        "OUTPUT_DIR = \"/content/extracted_logs\"\n",
        "REPORT_FILE = \"/content/structure_report.json\"\n",
        "SUMMARY_FILE = \"/content/summary_report.txt\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üîç ANALYSEUR DE STRUCTURE DES LOGS MOZILLA CI\")\n",
        "print(\"=\" * 80)\n",
        "print()\n",
        "\n",
        "# Cr√©er les r√©pertoires\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Fonction: Extraction des .rar\n",
        "def extract_rar_files(rar_paths):\n",
        "    print(\"üì¶ EXTRACTION DES FICHIERS .RAR\")\n",
        "    print(\"-\" * 80)\n",
        "    extracted_files = {}\n",
        "\n",
        "    for rar_path in rar_paths:\n",
        "        if not os.path.exists(rar_path):\n",
        "            continue\n",
        "\n",
        "        day = os.path.basename(rar_path).split('-')[-1].replace('.rar', '')\n",
        "        print(f\"\\nüìÇ Extraction de: {os.path.basename(rar_path)}\")\n",
        "\n",
        "        try:\n",
        "            day_dir = os.path.join(OUTPUT_DIR, f\"day_{day}\")\n",
        "            os.makedirs(day_dir, exist_ok=True)\n",
        "\n",
        "            with rarfile.RarFile(rar_path) as rf:\n",
        "                all_files = rf.namelist()\n",
        "                txt_files = [f for f in all_files if f.endswith('.txt')]\n",
        "\n",
        "                print(f\"   üìä Nombre total de fichiers .txt: {len(txt_files)}\")\n",
        "\n",
        "                if len(txt_files) > SAMPLE_SIZE:\n",
        "                    sampled_files = random.sample(txt_files, SAMPLE_SIZE)\n",
        "                    print(f\"   üìå √âchantillon s√©lectionn√©: {len(sampled_files)} fichiers\")\n",
        "                else:\n",
        "                    sampled_files = txt_files\n",
        "\n",
        "                for file in sampled_files:\n",
        "                    rf.extract(file, day_dir)\n",
        "\n",
        "                extracted_paths = []\n",
        "                for file in sampled_files:\n",
        "                    full_path = os.path.join(day_dir, file)\n",
        "                    if os.path.exists(full_path):\n",
        "                        extracted_paths.append(full_path)\n",
        "\n",
        "                extracted_files[day] = extracted_paths\n",
        "                print(f\"   ‚úÖ {len(extracted_paths)} fichiers extraits\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Erreur: {str(e)}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"‚úÖ EXTRACTION TERMIN√âE - Total: {sum(len(files) for files in extracted_files.values())} fichiers\")\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "    return extracted_files\n",
        "\n",
        "# Fonction: Analyse d'un log\n",
        "def analyze_log_structure(file_path):\n",
        "    analysis = {\n",
        "        'file_name': os.path.basename(file_path),\n",
        "        'file_size': 0,\n",
        "        'line_count': 0,\n",
        "        'header': {},\n",
        "        'sections': [],\n",
        "        'has_errors': False,\n",
        "        'error_count': 0,\n",
        "        'has_performance_metrics': False,\n",
        "        'timestamp_formats': set(),\n",
        "        'log_levels': Counter(),\n",
        "        'unique_patterns': set()\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        analysis['file_size'] = os.path.getsize(file_path)\n",
        "\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            lines = f.readlines()\n",
        "            analysis['line_count'] = len(lines)\n",
        "\n",
        "            # Parser le header\n",
        "            for i, line in enumerate(lines[:20]):\n",
        "                if ':' in line and not line.startswith('='):\n",
        "                    parts = line.split(':', 1)\n",
        "                    if len(parts) == 2:\n",
        "                        key = parts[0].strip()\n",
        "                        value = parts[1].strip()\n",
        "                        analysis['header'][key] = value\n",
        "\n",
        "            # Analyser le contenu\n",
        "            for line in lines:\n",
        "                # Sections\n",
        "                if 'Started' in line and '=========' in line:\n",
        "                    section_match = re.search(r\"Started\\s+(.+?)\\s+\\(results\", line)\n",
        "                    if section_match:\n",
        "                        analysis['sections'].append(section_match.group(1))\n",
        "\n",
        "                # Erreurs\n",
        "                if re.search(r'\\b(ERROR|FAIL|FAILURE|Exception|error)\\b', line, re.IGNORECASE):\n",
        "                    analysis['has_errors'] = True\n",
        "                    analysis['error_count'] += 1\n",
        "\n",
        "                # M√©triques\n",
        "                if re.search(r'(CPU|RAM|Memory|I/O|bytes|utilization)', line, re.IGNORECASE):\n",
        "                    analysis['has_performance_metrics'] = True\n",
        "\n",
        "                # Timestamps\n",
        "                timestamp_patterns = [\n",
        "                    r'\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2}',\n",
        "                    r'\\d{2}:\\d{2}:\\d{2}',\n",
        "                    r'\\d{10}\\.\\d+',\n",
        "                ]\n",
        "                for pattern in timestamp_patterns:\n",
        "                    if re.search(pattern, line):\n",
        "                        analysis['timestamp_formats'].add(pattern)\n",
        "\n",
        "                # Log levels\n",
        "                log_level_match = re.search(r'\\s+(INFO|DEBUG|WARNING|ERROR|CRITICAL)\\s+', line)\n",
        "                if log_level_match:\n",
        "                    analysis['log_levels'][log_level_match.group(1)] += 1\n",
        "\n",
        "                # Patterns\n",
        "                if 'TinderboxPrint' in line:\n",
        "                    analysis['unique_patterns'].add('TinderboxPrint')\n",
        "                if 'blobupload' in line:\n",
        "                    analysis['unique_patterns'].add('blobupload')\n",
        "                if 'master_lag' in line:\n",
        "                    analysis['unique_patterns'].add('master_lag')\n",
        "\n",
        "    except Exception as e:\n",
        "        analysis['parse_error'] = str(e)\n",
        "\n",
        "    # Convertir sets en listes\n",
        "    analysis['timestamp_formats'] = list(analysis['timestamp_formats'])\n",
        "    analysis['unique_patterns'] = list(analysis['unique_patterns'])\n",
        "    analysis['log_levels'] = dict(analysis['log_levels'])\n",
        "\n",
        "    return analysis\n",
        "\n",
        "# Fonction: Analyse globale\n",
        "def analyze_all_logs(extracted_files):\n",
        "    print(\"üîç ANALYSE DE LA STRUCTURE DES LOGS\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    global_report = {\n",
        "        'total_files_analyzed': 0,\n",
        "        'analysis_timestamp': datetime.now().isoformat(),\n",
        "        'days_analyzed': [],\n",
        "        'builder_types': Counter(),\n",
        "        'result_types': Counter(),\n",
        "        'file_sizes': [],\n",
        "        'line_counts': [],\n",
        "        'common_sections': Counter(),\n",
        "        'error_statistics': {'files_with_errors': 0, 'total_errors': 0},\n",
        "        'performance_metrics_present': 0,\n",
        "        'timestamp_formats_found': set(),\n",
        "        'log_levels_distribution': Counter(),\n",
        "        'unique_patterns_found': set(),\n",
        "        'detailed_analyses': []\n",
        "    }\n",
        "\n",
        "    for day, files in extracted_files.items():\n",
        "        print(f\"\\nüìÖ Analyse du jour {day}...\")\n",
        "        global_report['days_analyzed'].append(day)\n",
        "\n",
        "        for i, file_path in enumerate(files):\n",
        "            if i % 20 == 0:\n",
        "                print(f\"   Progression: {i}/{len(files)} fichiers analys√©s\")\n",
        "\n",
        "            analysis = analyze_log_structure(file_path)\n",
        "            global_report['total_files_analyzed'] += 1\n",
        "\n",
        "            if 'builder' in analysis['header']:\n",
        "                global_report['builder_types'][analysis['header']['builder']] += 1\n",
        "            if 'results' in analysis['header']:\n",
        "                global_report['result_types'][analysis['header']['results']] += 1\n",
        "\n",
        "            global_report['file_sizes'].append(analysis['file_size'])\n",
        "            global_report['line_counts'].append(analysis['line_count'])\n",
        "\n",
        "            for section in analysis['sections']:\n",
        "                global_report['common_sections'][section] += 1\n",
        "\n",
        "            if analysis['has_errors']:\n",
        "                global_report['error_statistics']['files_with_errors'] += 1\n",
        "                global_report['error_statistics']['total_errors'] += analysis['error_count']\n",
        "\n",
        "            if analysis['has_performance_metrics']:\n",
        "                global_report['performance_metrics_present'] += 1\n",
        "\n",
        "            global_report['timestamp_formats_found'].update(analysis['timestamp_formats'])\n",
        "\n",
        "            for level, count in analysis['log_levels'].items():\n",
        "                global_report['log_levels_distribution'][level] += count\n",
        "\n",
        "            global_report['unique_patterns_found'].update(analysis['unique_patterns'])\n",
        "\n",
        "            if len(global_report['detailed_analyses']) < 10:\n",
        "                global_report['detailed_analyses'].append(analysis)\n",
        "\n",
        "        print(f\"   ‚úÖ {len(files)} fichiers analys√©s pour le jour {day}\")\n",
        "\n",
        "    # Convertir sets en listes\n",
        "    global_report['timestamp_formats_found'] = list(global_report['timestamp_formats_found'])\n",
        "    global_report['unique_patterns_found'] = list(global_report['unique_patterns_found'])\n",
        "    global_report['builder_types'] = dict(global_report['builder_types'])\n",
        "    global_report['result_types'] = dict(global_report['result_types'])\n",
        "    global_report['common_sections'] = dict(global_report['common_sections'])\n",
        "    global_report['log_levels_distribution'] = dict(global_report['log_levels_distribution'])\n",
        "\n",
        "    # Statistiques\n",
        "    if global_report['file_sizes']:\n",
        "        global_report['avg_file_size'] = sum(global_report['file_sizes']) / len(global_report['file_sizes'])\n",
        "        global_report['min_file_size'] = min(global_report['file_sizes'])\n",
        "        global_report['max_file_size'] = max(global_report['file_sizes'])\n",
        "\n",
        "    if global_report['line_counts']:\n",
        "        global_report['avg_line_count'] = sum(global_report['line_counts']) / len(global_report['line_counts'])\n",
        "        global_report['min_line_count'] = min(global_report['line_counts'])\n",
        "        global_report['max_line_count'] = max(global_report['line_counts'])\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"‚úÖ ANALYSE TERMIN√âE\")\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "    return global_report\n",
        "\n",
        "# Fonction: G√©n√©ration des rapports\n",
        "def generate_reports(global_report):\n",
        "    print(\"üìù G√âN√âRATION DES RAPPORTS\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # JSON\n",
        "    with open(REPORT_FILE, 'w', encoding='utf-8') as f:\n",
        "        json.dump(global_report, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"‚úÖ Rapport JSON: {REPORT_FILE}\")\n",
        "\n",
        "    # Texte\n",
        "    summary = []\n",
        "    summary.append(\"=\" * 80)\n",
        "    summary.append(\"üìä RAPPORT D'ANALYSE DES LOGS MOZILLA CI\")\n",
        "    summary.append(\"=\" * 80)\n",
        "    summary.append(\"\")\n",
        "    summary.append(\"üî¢ STATISTIQUES GLOBALES\")\n",
        "    summary.append(\"-\" * 80)\n",
        "    summary.append(f\"Fichiers analys√©s: {global_report['total_files_analyzed']}\")\n",
        "    summary.append(f\"Jours: {', '.join(global_report['days_analyzed'])}\")\n",
        "    summary.append(\"\")\n",
        "    summary.append(\"üìè TAILLE DES FICHIERS\")\n",
        "    summary.append(\"-\" * 80)\n",
        "    summary.append(f\"Taille moyenne: {global_report.get('avg_file_size', 0):,.0f} octets ({global_report.get('avg_file_size', 0)/1024/1024:.2f} MB)\")\n",
        "    summary.append(\"\")\n",
        "    summary.append(\"üèóÔ∏è  TYPES DE BUILDERS (Top 10)\")\n",
        "    summary.append(\"-\" * 80)\n",
        "    for builder, count in sorted(global_report['builder_types'].items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "        summary.append(f\"  ‚Ä¢ {builder}: {count}\")\n",
        "    summary.append(\"\")\n",
        "    summary.append(\"‚úÖ R√âSULTATS DES BUILDS\")\n",
        "    summary.append(\"-\" * 80)\n",
        "    for result, count in sorted(global_report['result_types'].items(), key=lambda x: x[1], reverse=True):\n",
        "        percentage = (count / global_report['total_files_analyzed']) * 100\n",
        "        summary.append(f\"  ‚Ä¢ {result}: {count} ({percentage:.1f}%)\")\n",
        "    summary.append(\"\")\n",
        "    summary.append(\"=\" * 80)\n",
        "\n",
        "    with open(SUMMARY_FILE, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(summary))\n",
        "    print(f\"‚úÖ R√©sum√© texte: {SUMMARY_FILE}\")\n",
        "    print()\n",
        "    print('\\n'.join(summary))\n",
        "\n",
        "# EX√âCUTION PRINCIPALE\n",
        "print(\"üöÄ D√âMARRAGE...\\n\")\n",
        "\n",
        "# Trouver les fichiers .rar\n",
        "rar_files = [os.path.join('/content', f) for f in os.listdir('/content') if f.endswith('.rar')]\n",
        "\n",
        "if not rar_files:\n",
        "    print(\"‚ùå Aucun fichier .rar trouv√©!\")\n",
        "else:\n",
        "    print(f\"‚úÖ {len(rar_files)} fichier(s) .rar trouv√©(s)\\n\")\n",
        "    extracted_files = extract_rar_files(rar_files)\n",
        "\n",
        "    if extracted_files:\n",
        "        global_report = analyze_all_logs(extracted_files)\n",
        "        generate_reports(global_report)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"üéâ ANALYSE TERMIN√âE AVEC SUCC√àS!\")\n",
        "        print(\"=\" * 80)\n",
        "        print(\"\\nüìÅ Fichiers g√©n√©r√©s:\")\n",
        "        print(f\"   ‚Ä¢ {REPORT_FILE}\")\n",
        "        print(f\"   ‚Ä¢ {SUMMARY_FILE}\")\n"
      ],
      "metadata": {
        "id": "cell3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566164bc-f97d-48ee-df96-8d2cfdc63b61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üîç ANALYSEUR DE STRUCTURE DES LOGS MOZILLA CI\n",
            "================================================================================\n",
            "\n",
            "üöÄ D√âMARRAGE...\n",
            "\n",
            "‚úÖ 3 fichier(s) .rar trouv√©(s)\n",
            "\n",
            "üì¶ EXTRACTION DES FICHIERS .RAR\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìÇ Extraction de: log-2018-06-01.rar\n",
            "   üìä Nombre total de fichiers .txt: 1452\n",
            "   üìå √âchantillon s√©lectionn√©: 100 fichiers\n",
            "   ‚úÖ 100 fichiers extraits\n",
            "\n",
            "üìÇ Extraction de: log-2018-06-19.rar\n",
            "   üìä Nombre total de fichiers .txt: 2179\n",
            "   üìå √âchantillon s√©lectionn√©: 100 fichiers\n",
            "   ‚úÖ 100 fichiers extraits\n",
            "\n",
            "üìÇ Extraction de: log-2018-06-20.rar\n",
            "   üìä Nombre total de fichiers .txt: 861\n",
            "   üìå √âchantillon s√©lectionn√©: 100 fichiers\n",
            "   ‚úÖ 100 fichiers extraits\n",
            "\n",
            "================================================================================\n",
            "‚úÖ EXTRACTION TERMIN√âE - Total: 300 fichiers\n",
            "================================================================================\n",
            "\n",
            "üîç ANALYSE DE LA STRUCTURE DES LOGS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìÖ Analyse du jour 01...\n",
            "   Progression: 0/100 fichiers analys√©s\n",
            "   Progression: 20/100 fichiers analys√©s\n",
            "   Progression: 40/100 fichiers analys√©s\n",
            "   Progression: 60/100 fichiers analys√©s\n",
            "   Progression: 80/100 fichiers analys√©s\n",
            "   ‚úÖ 100 fichiers analys√©s pour le jour 01\n",
            "\n",
            "üìÖ Analyse du jour 19...\n",
            "   Progression: 0/100 fichiers analys√©s\n",
            "   Progression: 20/100 fichiers analys√©s\n",
            "   Progression: 40/100 fichiers analys√©s\n",
            "   Progression: 60/100 fichiers analys√©s\n",
            "   Progression: 80/100 fichiers analys√©s\n",
            "   ‚úÖ 100 fichiers analys√©s pour le jour 19\n",
            "\n",
            "üìÖ Analyse du jour 20...\n",
            "   Progression: 0/100 fichiers analys√©s\n",
            "   Progression: 20/100 fichiers analys√©s\n",
            "   Progression: 40/100 fichiers analys√©s\n",
            "   Progression: 60/100 fichiers analys√©s\n",
            "   Progression: 80/100 fichiers analys√©s\n",
            "   ‚úÖ 100 fichiers analys√©s pour le jour 20\n",
            "\n",
            "================================================================================\n",
            "‚úÖ ANALYSE TERMIN√âE\n",
            "================================================================================\n",
            "\n",
            "üìù G√âN√âRATION DES RAPPORTS\n",
            "--------------------------------------------------------------------------------\n",
            "‚úÖ Rapport JSON: /content/structure_report.json\n",
            "‚úÖ R√©sum√© texte: /content/summary_report.txt\n",
            "\n",
            "================================================================================\n",
            "üìä RAPPORT D'ANALYSE DES LOGS MOZILLA CI\n",
            "================================================================================\n",
            "\n",
            "üî¢ STATISTIQUES GLOBALES\n",
            "--------------------------------------------------------------------------------\n",
            "Fichiers analys√©s: 300\n",
            "Jours: 01, 19, 20\n",
            "\n",
            "üìè TAILLE DES FICHIERS\n",
            "--------------------------------------------------------------------------------\n",
            "Taille moyenne: 3,131,314 octets (2.99 MB)\n",
            "\n",
            "üèóÔ∏è  TYPES DE BUILDERS (Top 10)\n",
            "--------------------------------------------------------------------------------\n",
            "  ‚Ä¢ mozilla-esr52_xp_ix-debug_test-mochitest-devtools-chrome-6: 4\n",
            "  ‚Ä¢ mozilla-esr52_ubuntu32_vm-debug_test-mochitest-e10s-7: 2\n",
            "  ‚Ä¢ mozilla-esr52_ubuntu64_vm_test_pgo-cppunit: 2\n",
            "  ‚Ä¢ mozilla-esr52_ubuntu32_vm_test_pgo-mochitest-e10s-devtools-chrome-7: 2\n",
            "  ‚Ä¢ mozilla-esr52_win8_64-debug_test-web-platform-tests-reftests-e10s: 2\n",
            "  ‚Ä¢ mozilla-esr52_win8_64_test_pgo-mochitest-browser-chrome-5: 2\n",
            "  ‚Ä¢ mozilla-esr52_win7_vm_test_pgo-mochitest-e10s-1: 2\n",
            "  ‚Ä¢ mozilla-esr52_ubuntu64_vm_test_pgo-mochitest-jetpack: 2\n",
            "  ‚Ä¢ mozilla-esr52_ubuntu64_vm_test_pgo-mochitest-gpu-e10s: 2\n",
            "  ‚Ä¢ mozilla-esr52_ubuntu32_vm-debug_test-mochitest-4: 2\n",
            "\n",
            "‚úÖ R√âSULTATS DES BUILDS\n",
            "--------------------------------------------------------------------------------\n",
            "  ‚Ä¢ success (0): 281 (93.7%)\n",
            "  ‚Ä¢ failure (2): 11 (3.7%)\n",
            "  ‚Ä¢ warnings (1): 6 (2.0%)\n",
            "  ‚Ä¢ retry (5): 2 (0.7%)\n",
            "\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üéâ ANALYSE TERMIN√âE AVEC SUCC√àS!\n",
            "================================================================================\n",
            "\n",
            "üìÅ Fichiers g√©n√©r√©s:\n",
            "   ‚Ä¢ /content/structure_report.json\n",
            "   ‚Ä¢ /content/summary_report.txt\n"
          ]
        }
      ]
    }
  ]
}